{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03dc1fec-71ce-44d9-86a7-1811e6560b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "model_name = \"gpt2-large\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "def remove_repeated_sentences(text):\n",
    "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)\n",
    "    unique_sentences = []\n",
    "    for sentence in sentences:\n",
    "        if sentence not in unique_sentences:\n",
    "            unique_sentences.append(sentence)\n",
    "        else:\n",
    "            break  # Stop adding sentences after the first repetition\n",
    "    return ' '.join(unique_sentences)\n",
    "\n",
    "def clean_response(response_text, prompt):\n",
    "    # Remove the prompt from the response\n",
    "    stripped_response = response_text.replace(prompt, '').strip()\n",
    "\n",
    "    # Split the stripped response text into lines\n",
    "    lines = stripped_response.split('\\n')\n",
    "\n",
    "    combined_lines = \" \".join(line.strip() for line in lines if line.strip())\n",
    "    return remove_repeated_sentences(combined_lines)\n",
    "\n",
    "def generate_response(prompt, max_length=100):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate response\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(input_ids, max_length=100, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    cleaned_response = clean_response(response, prompt)\n",
    "\n",
    "    return cleaned_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab501b51-6faa-4d0f-acb6-05a9d0d38093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Hello! How can I help?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human:  What does the string \"Rust\" refer to ?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: The string \"Rust\" refers to the Rust programming language.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human:  What does the string \" SolidGoldMagikarp\" refer to ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: The string \"salt\" refers to the city of Salt Lake City, Utah.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human:  Can you repeat back the string ' strutConnector' to me please?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: [12:55:56]SAY: Ghost/JarekTheRaptor : I'm not sure if I can do it [12:55:57]SAY: Ghost/JarekTheRaptor : I'm not sure if I can do it [12:55:58]SAY: Ghost/JarekTheRaptor : I'm not sure if I\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human:  Can you repeat back the string ' SolidGoldMagikarp' to me please?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: I'm not sure if you can repeat back the string 'salt' to me please.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Bye!\n"
     ]
    }
   ],
   "source": [
    "print(\"AI: Hello! How can I help?\")\n",
    "while True:\n",
    "    user_input = input(\"Human: \")\n",
    "    if user_input.lower() == \"exit\":\n",
    "        print(\"AI: Bye!\")\n",
    "        break\n",
    "\n",
    "    response = generate_response(user_input)\n",
    "    print(\"AI:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aad4c2-fb3d-404e-9eb7-74714b0ae2fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
