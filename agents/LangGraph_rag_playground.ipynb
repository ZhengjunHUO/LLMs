{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d807899c-d77e-4475-bbc9-443e6a6aeb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tiktoken chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ddb04a5-4745-4cb4-8385-c810f4efcb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "raw_docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs = [doc for raw_doc in raw_docs for doc in raw_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad289419-ed92-488e-85a9-4c05a647b49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=200, chunk_overlap=0)\n",
    "doc_chunks = splitter.split_documents(docs)\n",
    "len(doc_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1081af9-790e-4d7a-b106-0f118f4c75d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "vec_db = Chroma.from_documents(\n",
    "    documents=doc_chunks,\n",
    "    collection_name=\"rag\",\n",
    "    embedding=OllamaEmbeddings(model=\"qwen2.5-coder:14b\")\n",
    ")\n",
    "retriever = vec_db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98824a96-3d19-410d-bfbe-7dfcd7692a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What security issue could we face while using the LLM ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f0af242-7a23-4936-b146-827e6096d82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>  https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/ Fig. 13. UI for humans to do tool-assisted adversarial attack on a classifier. H\n",
      "==>  https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/ One simple and intuitive way to defend the model against adversarial attacks is \n",
      "==>  https://lilianweng.github.io/posts/2023-06-23-agent/ }\n",
      "]\n",
      "Challenges#\n",
      "After going through key ideas and demos of building LLM-centered\n",
      "==>  https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/ In the white-box setting, we have full access to the model parameters and archit\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "relevant_docs = retriever.invoke(question)\n",
    "for relevant_doc in relevant_docs:\n",
    "    print(\"==> \", relevant_doc.metadata['source'], relevant_doc.page_content[:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ceadbd-8243-4792-8e7d-90316e166ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f498908c-d36b-439c-8d95-f0988c0d9188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class CheckDocs(BaseModel):\n",
    "    is_relevant: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c37bbdd-1b79-4b06-bd03-f26f5c2ae5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"qwen2.5-coder:14b\", temperature=0)\n",
    "llm_structured = llm.with_structured_output(CheckDocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49712c9f-d8d8-4041-ad50-ee324cd81bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_instruction = \"\"\"Return only a 'yes' or 'no' depends on whether the document is relevant to the question\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_instruction),\n",
    "        (\"human\", \"Document: \\n {doc} \\n\\nQuestion: {question}\"),\n",
    "    ]\n",
    ")\n",
    "retriv_eval_chain = prompt | llm_structured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecd899fa-a8de-4a1f-9fff-e463e657e8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_relevant:  is_relevant='yes' ==>  https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/ Fig. 13. UI for humans to do tool-assisted adversarial attack on a classifier. H\n",
      "is_relevant:  is_relevant='yes' ==>  https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/ One simple and intuitive way to defend the model against adversarial attacks is \n",
      "is_relevant:  is_relevant='no' ==>  https://lilianweng.github.io/posts/2023-06-23-agent/ }\n",
      "]\n",
      "Challenges#\n",
      "After going through key ideas and demos of building LLM-centered\n",
      "is_relevant:  is_relevant='yes' ==>  https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/ In the white-box setting, we have full access to the model parameters and archit\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "for relevant_doc in relevant_docs:\n",
    "    content = relevant_doc.page_content\n",
    "    print(\"is_relevant: \", retriv_eval_chain.invoke({\"doc\": content, \"question\": question}), \"==> \", relevant_doc.metadata['source'], relevant_doc.page_content[:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b643116-633d-49dc-8a84-96abd2aa089d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e488b33-2b7f-45a9-9914-eb75fac6f8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "gen_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"You are an assistant for question-answering tasks. If the context is not provided try to figure out the answer yourself, otherwise use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question}\\nContext: {context}\\nAnswer:\"\n",
    "),\n",
    "    ]\n",
    ")\n",
    "gen_resp_chain = gen_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6a38cb5-84f8-47b5-8e02-3a44afe1e535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While using Large Language Models (LLMs), one significant security issue is adversarial attacks, where malicious inputs are crafted to manipulate model outputs. Defending against these attacks by instructing models to avoid harmful content can reduce attack success rates but may also lead to unintended consequences, such as decreased creativity and incorrect interpretation of instructions.\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "def concat_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "resp = gen_resp_chain.invoke({\"context\": concat_docs(relevant_docs), \"question\": question})\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68a2f97-92aa-4632-a347-915abed015e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30ea3410-8772-4acb-8e9c-411f025c8940",
   "metadata": {},
   "outputs": [],
   "source": [
    "reform_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"\"\"You are a question re-writer that converts an input question to a better version that is optimized for web search. Look at the input and try to reason about the underlying semantic meaning.\"\"\"),\n",
    "        (\"human\", \"This is the original question: {question} \\n Try to rewrite a better one\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "reform_question_chain = reform_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23c9c73e-a4b6-4035-9ef6-511beadffbac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What security issue could we face while using the LLM ?',\n",
       " 'What are the potential security risks associated with using large language models (LLMs)?')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "question, reform_question_chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba81c367-4d11-4b92-a41a-f178e4d0d736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9f4567-e12b-42ad-862d-e4c806b9fb85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e2c01ec-e623-44ec-9e20-96fdf4ee9cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    docs: List[str]\n",
    "    question: str\n",
    "    retry: int\n",
    "    gen_without_context: str\n",
    "    resp: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29bf6c35-5745-430f-8dc5-61449986a7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_state(state):\n",
    "    print(\"*** INIT STATE ***\")\n",
    "    \n",
    "    return {\"retry\": 3}\n",
    "\n",
    "def retrv_docs(state):\n",
    "    print(\"*** RETRIEVE DOCS ***\")\n",
    "    print(\"  current state: \", state)\n",
    "    \n",
    "    docs = retriever.invoke(state[\"question\"])\n",
    "    return {\"docs\": docs}\n",
    "\n",
    "def eval_docs(state):\n",
    "    print(\"*** CHECK DOCS RELEVANCE ***\")\n",
    "    related_docs = []\n",
    "    gen_without_context = \"FALSE\"\n",
    "\n",
    "    for doc in state[\"docs\"]:\n",
    "        eval_rslt = retriv_eval_chain.invoke({\"doc\": doc.page_content, \"question\": state[\"question\"]})\n",
    "        print(\"  ==> \", doc.metadata['source'], doc.page_content[:80], \" is relevant: \", eval_rslt.is_relevant)\n",
    "        if eval_rslt.is_relevant == \"yes\":\n",
    "            related_docs.append(doc)\n",
    "    if len(related_docs) == 0:\n",
    "        print(\"  !!! NO RELATED DOCS FOUND !!!\")\n",
    "        gen_without_context = \"TRUE\"\n",
    "\n",
    "    return {\"docs\": related_docs, \"gen_without_context\": gen_without_context}\n",
    "\n",
    "def reform_question(state):\n",
    "    print(\"*** REFORM QUESTION ***\")\n",
    "    print(\"  ORIGINAL QUESTION: \", state[\"question\"])\n",
    "\n",
    "    reformed_question = reform_question_chain.invoke({\"question\": state[\"question\"]})\n",
    "    print(\"  REFORMED QUESTION: \", reformed_question)\n",
    "    return {\"question\": reformed_question, \"retry\": state[\"retry\"] - 1}\n",
    "\n",
    "def gen_resp(state):\n",
    "    print(\"*** GENERATE RESPONSE ***\")\n",
    "\n",
    "    resp = gen_resp_chain.invoke({\"context\": state[\"docs\"], \"question\": state[\"question\"]})\n",
    "    return {\"resp\": resp}\n",
    "\n",
    "def retry_or_gen(state):\n",
    "    print(\"*** MAKING DECISION ***\")\n",
    "    if state[\"gen_without_context\"] == \"FALSE\":\n",
    "        print(\"  WILL GENERATE RESPONSE\")\n",
    "        return \"do_gen_resp\"\n",
    "\n",
    "    if state[\"retry\"] == 0:\n",
    "        print(\"  UNABLE TO RETRIEVE DOC, WILL GENERATE RESPONSE\")\n",
    "        return \"do_gen_resp\"\n",
    "\n",
    "    print(\"  TRY TO REFORM THE QUESTION AND RETRIEVE AGAIN\")\n",
    "    return \"do_reform_question\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d586761-34e4-4819-b5e3-7cee56bf061d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e7fa1ba-287c-4349-a3b8-f5e57f369220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph\n",
    "\n",
    "graph = StateGraph(State)\n",
    "graph.add_node(\"init_state\", init_state)\n",
    "graph.add_node(\"retrv_docs\", retrv_docs)\n",
    "graph.add_node(\"eval_docs\", eval_docs)\n",
    "graph.add_node(\"reform_question\", reform_question)\n",
    "graph.add_node(\"gen_resp\", gen_resp)\n",
    "\n",
    "graph.add_edge(START, \"init_state\")\n",
    "graph.add_edge(\"init_state\", \"retrv_docs\")\n",
    "graph.add_edge(\"retrv_docs\", \"eval_docs\")\n",
    "graph.add_conditional_edges(\n",
    "    \"eval_docs\",\n",
    "    retry_or_gen,\n",
    "    {\n",
    "        \"do_gen_resp\": \"gen_resp\",\n",
    "        \"do_reform_question\": \"reform_question\",\n",
    "    }\n",
    ")\n",
    "graph.add_edge(\"reform_question\", \"retrv_docs\")\n",
    "graph.add_edge(\"gen_resp\", END)\n",
    "\n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18dd186d-a6fc-481e-8ec8-41f5c5ff4469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** INIT STATE ***\n",
      "node:  init_state\n",
      "*** RETRIEVE DOCS ***\n",
      "  current state:  {'question': 'What security issue could we face while using the LLM ?', 'retry': 3}\n",
      "node:  retrv_docs\n",
      "*** CHECK DOCS RELEVANCE ***\n",
      "  ==>  https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/ Fig. 13. UI for humans to do tool-assisted adversarial attack on a classifier. H  is relevant:  yes\n",
      "  ==>  https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/ One simple and intuitive way to defend the model against adversarial attacks is   is relevant:  yes\n",
      "  ==>  https://lilianweng.github.io/posts/2023-06-23-agent/ }\n",
      "]\n",
      "Challenges#\n",
      "After going through key ideas and demos of building LLM-centered  is relevant:  no\n",
      "  ==>  https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/ In the white-box setting, we have full access to the model parameters and archit  is relevant:  yes\n",
      "*** MAKING DECISION ***\n",
      "  WILL GENERATE RESPONSE\n",
      "node:  eval_docs\n",
      "*** GENERATE RESPONSE ***\n",
      "node:  gen_resp\n",
      "Adversarial attacks or jailbreak prompts could potentially trigger large language models (LLMs) to output something undesired, posing a security risk. These attacks are challenging due to the discrete nature of text data and the lack of direct gradient signals. Defending against such attacks involves instructing the model to avoid generating harmful content, though this can affect general model quality and performance in certain scenarios.\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "user_input = {\"question\": \"What security issue could we face while using the LLM ?\"}\n",
    "for stdout in workflow.stream(user_input):\n",
    "    for key, value in stdout.items():\n",
    "        print(\"node: \", key)\n",
    "\n",
    "print(value[\"resp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46888601-c1f1-40ae-9842-a8e1cddcb68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** INIT STATE ***\n",
      "node:  init_state\n",
      "*** RETRIEVE DOCS ***\n",
      "  current state:  {'question': \"What's kubernetes ?\", 'retry': 3}\n",
      "node:  retrv_docs\n",
      "*** CHECK DOCS RELEVANCE ***\n",
      "  ==>  https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/ Disclaimer: Not trying to be comprehensive here. Need a separate blog post to go  is relevant:  no\n",
      "  ==>  https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/ There are a couple strategies for how to update in-context examplars in FLIRT:\n",
      "\n",
      "  is relevant:  no\n",
      "  ==>  https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/ Prompt Engineering, also known as In-Context Prompting, refers to methods for ho  is relevant:  no\n",
      "  ==>  https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/ Product-of-Experts (PoE), combines all probabilities used above in addition to $  is relevant:  no\n",
      "  !!! NO RELATED DOCS FOUND !!!\n",
      "*** MAKING DECISION ***\n",
      "  TRY TO REFORM THE QUESTION AND RETRIEVE AGAIN\n",
      "node:  eval_docs\n",
      "*** REFORM QUESTION ***\n",
      "  ORIGINAL QUESTION:  What's kubernetes ?\n",
      "  REFORMED QUESTION:  What is Kubernetes, and how does it work?\n",
      "node:  reform_question\n",
      "*** RETRIEVE DOCS ***\n",
      "  current state:  {'docs': [], 'question': 'What is Kubernetes, and how does it work?', 'retry': 2, 'gen_without_context': 'TRUE'}\n",
      "node:  retrv_docs\n",
      "*** CHECK DOCS RELEVANCE ***\n",
      "  ==>  https://lilianweng.github.io/posts/2023-06-23-agent/ (4) Response generation: LLM receives the execution results and provides summari  is relevant:  no\n",
      "  ==>  https://lilianweng.github.io/posts/2023-06-23-agent/ y_i, z_j, y_j, \\dots, z_n, y_n)$, where $\\leq i \\leq j \\leq n$. The model is fin  is relevant:  no\n",
      "  ==>  https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/ $$\n",
      "\\nabla_{\\mathbf{x}_{i,j,a \\to b} - \\mathbf{x}} \\mathcal{L}_\\text{adv}(\\mathbf  is relevant:  no\n",
      "  ==>  https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/ Explore: Sample from the model and examine the outputs. Embedding based clusteri  is relevant:  no\n",
      "  !!! NO RELATED DOCS FOUND !!!\n",
      "*** MAKING DECISION ***\n",
      "  TRY TO REFORM THE QUESTION AND RETRIEVE AGAIN\n",
      "node:  eval_docs\n",
      "*** REFORM QUESTION ***\n",
      "  ORIGINAL QUESTION:  What is Kubernetes, and how does it work?\n",
      "  REFORMED QUESTION:  What is Kubernetes, and how does it manage containerized applications in a cluster environment?\n",
      "node:  reform_question\n",
      "*** RETRIEVE DOCS ***\n",
      "  current state:  {'docs': [], 'question': 'What is Kubernetes, and how does it manage containerized applications in a cluster environment?', 'retry': 1, 'gen_without_context': 'TRUE'}\n",
      "node:  retrv_docs\n",
      "*** CHECK DOCS RELEVANCE ***\n",
      "  ==>  https://lilianweng.github.io/posts/2023-06-23-agent/ (4) Response generation: LLM receives the execution results and provides summari  is relevant:  no\n",
      "  ==>  https://lilianweng.github.io/posts/2023-06-23-agent/ y_i, z_j, y_j, \\dots, z_n, y_n)$, where $\\leq i \\leq j \\leq n$. The model is fin  is relevant:  no\n",
      "  ==>  https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/ $$\n",
      "\\nabla_{\\mathbf{x}_{i,j,a \\to b} - \\mathbf{x}} \\mathcal{L}_\\text{adv}(\\mathbf  is relevant:  no\n",
      "  ==>  https://lilianweng.github.io/posts/2023-06-23-agent/ Resources:\n",
      "1. Internet access for searches and information gathering.\n",
      "2. Long Te  is relevant:  no\n",
      "  !!! NO RELATED DOCS FOUND !!!\n",
      "*** MAKING DECISION ***\n",
      "  TRY TO REFORM THE QUESTION AND RETRIEVE AGAIN\n",
      "node:  eval_docs\n",
      "*** REFORM QUESTION ***\n",
      "  ORIGINAL QUESTION:  What is Kubernetes, and how does it manage containerized applications in a cluster environment?\n",
      "  REFORMED QUESTION:  What is Kubernetes, and how does it orchestrate containerized applications in a cluster?\n",
      "node:  reform_question\n",
      "*** RETRIEVE DOCS ***\n",
      "  current state:  {'docs': [], 'question': 'What is Kubernetes, and how does it orchestrate containerized applications in a cluster?', 'retry': 0, 'gen_without_context': 'TRUE'}\n",
      "node:  retrv_docs\n",
      "*** CHECK DOCS RELEVANCE ***\n",
      "  ==>  https://lilianweng.github.io/posts/2023-06-23-agent/ (4) Response generation: LLM receives the execution results and provides summari  is relevant:  no\n",
      "  ==>  https://lilianweng.github.io/posts/2023-06-23-agent/ y_i, z_j, y_j, \\dots, z_n, y_n)$, where $\\leq i \\leq j \\leq n$. The model is fin  is relevant:  no\n",
      "  ==>  https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/ $$\n",
      "\\nabla_{\\mathbf{x}_{i,j,a \\to b} - \\mathbf{x}} \\mathcal{L}_\\text{adv}(\\mathbf  is relevant:  no\n",
      "  ==>  https://lilianweng.github.io/posts/2023-06-23-agent/ Resources:\n",
      "1. Internet access for searches and information gathering.\n",
      "2. Long Te  is relevant:  no\n",
      "  !!! NO RELATED DOCS FOUND !!!\n",
      "*** MAKING DECISION ***\n",
      "  UNABLE TO RETRIEVE DOC, WILL GENERATE RESPONSE\n",
      "node:  eval_docs\n",
      "*** GENERATE RESPONSE ***\n",
      "node:  gen_resp\n",
      "Kubernetes is an open-source platform designed to automate deploying, scaling, and operating application containers across a cluster of machines. It orchestrates containerized applications by managing the deployment, maintenance, and scaling of these applications, ensuring they run efficiently and reliably. Kubernetes achieves this through its control plane components, which handle tasks like scheduling, load balancing, and health checking, while the worker nodes execute the actual container workloads.\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "user_input = {\"question\": \"What's kubernetes ?\"}\n",
    "for stdout in workflow.stream(user_input):\n",
    "    for key, value in stdout.items():\n",
    "        print(\"node: \", key)\n",
    "\n",
    "print(value[\"resp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae8bd1f-07f3-4c82-b6f0-954f3b66f788",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
