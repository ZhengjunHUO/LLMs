{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d807899c-d77e-4475-bbc9-443e6a6aeb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tiktoken chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ddb04a5-4745-4cb4-8385-c810f4efcb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "raw_docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs = [doc for raw_doc in raw_docs for doc in raw_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad289419-ed92-488e-85a9-4c05a647b49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=200, chunk_overlap=0)\n",
    "doc_chunks = splitter.split_documents(docs)\n",
    "len(doc_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1081af9-790e-4d7a-b106-0f118f4c75d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "vec_db = Chroma.from_documents(\n",
    "    documents=doc_chunks,\n",
    "    collection_name=\"rag\",\n",
    "    embedding=OllamaEmbeddings(model=\"qwen2.5-coder:14b\")\n",
    ")\n",
    "retriever = vec_db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98824a96-3d19-410d-bfbe-7dfcd7692a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What security issue could we face while using the LLM ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f0af242-7a23-4936-b146-827e6096d82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>  https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/ One simple and intuitive way to defend the model against adversarial attacks is \n",
      "==>  https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/ Fig. 13. UI for humans to do tool-assisted adversarial attack on a classifier. H\n",
      "==>  https://lilianweng.github.io/posts/2023-06-23-agent/ }\n",
      "]\n",
      "Challenges#\n",
      "After going through key ideas and demos of building LLM-centered\n",
      "==>  https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/ In the white-box setting, we have full access to the model parameters and archit\n"
     ]
    }
   ],
   "source": [
    "relevant_docs = retriever.invoke(question)\n",
    "for relevant_doc in relevant_docs:\n",
    "    print(\"==> \", relevant_doc.metadata['source'], relevant_doc.page_content[:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f5d78d-3801-477b-9648-4f410ddd9ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
